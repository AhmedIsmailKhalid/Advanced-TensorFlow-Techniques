{"cells":[{"cell_type":"markdown","metadata":{"id":"FFXxdO4PjXg5"},"source":["# One Device Strategy\n","\n","In this notebook, we'll explore how to set up a [One Device Strategy](https://www.tensorflow.org/api_docs/python/tf/distribute/OneDeviceStrategy). This strategy is especially useful for deliberately testing code on a single device. Employing this strategy is a prudent first step before advancing to more complex distribution strategies that operate across multiple devices. This approach helps in identifying issues early in the development process, ensuring that our code functions correctly in a simpler environment before transitioning to distributed computing configurations."]},{"cell_type":"markdown","metadata":{"id":"yTGJkJpyjXg6"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rFpbGH-egdhC"},"outputs":[],"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","import tensorflow_datasets as tfds\n","\n","tfds.disable_progress_bar()"]},{"cell_type":"markdown","metadata":{"id":"tJa-pX8ZjXg7"},"source":["## Define the Distribution Strategy\n","\n","We can list the available devices on our machine and specify a particular device type to use. This step is crucial for verifying the exact device name that we need to pass into `tf.distribute.OneDeviceStrategy()`. By explicitly identifying and specifying the device, we ensure that TensorFlow directs its computational tasks to the correct hardware, whether it's a specific GPU or CPU. This precise control is essential for optimizing performance and for targeted testing on a single device before scaling up to more complex multi-device strategies."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uYQy3R6NjXg7","outputId":"7d3b4c03-3173-4e2d-9986-c0141fbce7f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"]}],"source":["# Choose a device type such as CPU or GPU\n","devices = tf.config.list_physical_devices('GPU')\n","print(devices[0])\n","\n","# We'll see that the name will look something like \"/physical_device:GPU:0\"\n","# Just take the GPU:0 part and use that as the name\n","gpu_name = \"GPU:0\"\n","\n","# Define the strategy and pass in the device name\n","one_strategy = tf.distribute.OneDeviceStrategy(device=gpu_name)"]},{"cell_type":"markdown","metadata":{"id":"qFQhNkVtjXg8"},"source":["## Parameters\n","\n","We'll set up a few global variables to establish the foundational parameters for our model and dataset. These variables will help streamline the configuration process, ensuring that our setup remains organized and consistent throughout the training and evaluation phases. This approach not only enhances code readability but also simplifies adjustments and scalability in future development stages."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P_OV1G0J0bx8","outputId":"5691ed21-b3f5-4498-b7d4-9574c009614e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using https://tfhub.dev/tensorflow/resnet_50/feature_vector/1 with input size (224, 224)\n"]}],"source":["pixels = 224\n","MODULE_HANDLE = 'https://tfhub.dev/tensorflow/resnet_50/feature_vector/1'\n","IMAGE_SIZE = (pixels, pixels)\n","BATCH_SIZE = 32\n","\n","print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))"]},{"cell_type":"markdown","metadata":{"id":"WA0u12yLjXg9"},"source":["## Download and Prepare the Dataset\n","\n","We will use the [Cats vs Dogs](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs) dataset, which we will fetch using TensorFlow Datasets (TFDS). This dataset is a popular choice for practicing image classification techniques, providing a balanced set of images of cats and dogs. Using TFDS for fetching the dataset ensures that we can easily access and preprocess the data, making it ready for training our model efficiently."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1HCFBMh-1gaX","outputId":"eef1ed5f-87a2-4f33-af47-feb1c249f317"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1mDownloading and preparing dataset cats_vs_dogs/4.0.0 (download: 786.68 MiB, generated: Unknown size, total: 786.68 MiB) to /root/tensorflow_datasets/cats_vs_dogs/4.0.0...\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:1738 images were corrupted and were skipped\n"]},{"name":"stdout","output_type":"stream","text":["Shuffling and writing examples to /root/tensorflow_datasets/cats_vs_dogs/4.0.0.incomplete9O56S2/cats_vs_dogs-train.tfrecord\n","\u001b[1mDataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/4.0.0. Subsequent calls will reuse this data.\u001b[0m\n"]}],"source":["splits = ['train[:80%]', 'train[80%:90%]', 'train[90%:]']\n","\n","(train_examples, validation_examples, test_examples), info = tfds.load('cats_vs_dogs', with_info=True, as_supervised=True, split=splits)\n","\n","num_examples = info.splits['train'].num_examples\n","num_classes = info.features['label'].num_classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5jfUDRQN1kfk"},"outputs":[],"source":["# Resize the image and normalize pixel values\n","def format_image(image, label):\n","    image = tf.image.resize(image, IMAGE_SIZE) / 255.0\n","    return  image, label"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WRBF8Vp01uaE"},"outputs":[],"source":["# Prepare batches\n","train_batches = train_examples.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n","validation_batches = validation_examples.map(format_image).batch(BATCH_SIZE).prefetch(1)\n","test_batches = test_examples.map(format_image).batch(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MxggWg9m11P1","outputId":"4036342c-4b18-455a-d2cb-18fe7606f5de"},"outputs":[{"name":"stdout","output_type":"stream","text":["(32, 224, 224, 3)\n"]}],"source":["# Check if the batches have the correct size and the images have the correct shape\n","for image_batch, label_batch in train_batches.take(1):\n","    pass\n","\n","print(image_batch.shape)"]},{"cell_type":"markdown","metadata":{"id":"oC4I8W47jXg_"},"source":["## Define and Configure the Model\n","\n","As with other TensorFlow distribution strategies, setting up our model with the One Device Strategy requires minimal code changes. To streamline the process, let's first define a utility function that will both build and compile our model. This function will encapsulate all necessary steps for model construction, including defining the architecture and setting up the compilation parameters like the optimizer, loss function, and metrics. This approach ensures that our model setup is not only efficient but also easily adaptable to different scenarios or distribution strategies."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wx8MEwUl1300"},"outputs":[],"source":["# Freeze the layer weights of our feature extractor during training\n","do_fine_tuning = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WKLytydu1_qt"},"outputs":[],"source":["def build_and_compile_model():\n","    print(\"Building model with\", MODULE_HANDLE)\n","\n","    # Configure the feature extractor fetched from TF Hub\n","    feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n","                                   input_shape=IMAGE_SIZE + (3,),\n","                                   trainable=do_fine_tuning)\n","\n","    # Define the model\n","    model = tf.keras.Sequential([\n","      feature_extractor,\n","      # Append a dense with softmax for the number of classes\n","      tf.keras.layers.Dense(num_classes, activation='softmax')\n","    ])\n","\n","    # Display summary\n","    model.summary()\n","\n","    # Configure the optimizer, loss and metrics\n","    optimizer = tf.keras.optimizers.SGD(lr=0.002, momentum=0.9) if do_fine_tuning else 'adam'\n","    model.compile(optimizer=optimizer,\n","                loss='sparse_categorical_crossentropy',\n","                metrics=['accuracy'])\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"hAKixXeTjXhB"},"source":["We can now call our model-building function within the strategy scope. This practice places all variables and computations on the device we specified earlier. By invoking the function in this context, TensorFlow ensures that all model components are appropriately allocated to the designated device, optimizing computational efficiency and resource utilization. This step is crucial for leveraging the full capabilities of the selected hardware during model training and operations.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sDenpJX-2EhD","outputId":"aba89825-1a1b-4574-8f18-3b1a07942fb9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Building model with https://tfhub.dev/tensorflow/resnet_50/feature_vector/1\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","keras_layer (KerasLayer)     (None, 2048)              23561152  \n","_________________________________________________________________\n","dense (Dense)                (None, 2)                 4098      \n","=================================================================\n","Total params: 23,565,250\n","Trainable params: 4,098\n","Non-trainable params: 23,561,152\n","_________________________________________________________________\n"]}],"source":["# Build and compile under the strategy scope\n","with one_strategy.scope():\n","    model = build_and_compile_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7L4C5KKs3fal","outputId":"7179ac79-742a-4a21-8825-81ca36b88d9e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","582/582 [==============================] - 106s 115ms/step - loss: 0.0364 - accuracy: 0.9874 - val_loss: 0.0346 - val_accuracy: 0.9897\n","Epoch 2/5\n","582/582 [==============================] - 72s 117ms/step - loss: 0.0193 - accuracy: 0.9935 - val_loss: 0.0268 - val_accuracy: 0.9918\n","Epoch 3/5\n","582/582 [==============================] - 72s 117ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.0259 - val_accuracy: 0.9923\n","Epoch 4/5\n","582/582 [==============================] - 72s 116ms/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.0314 - val_accuracy: 0.9910\n","Epoch 5/5\n","582/582 [==============================] - 71s 116ms/step - loss: 0.0094 - accuracy: 0.9965 - val_loss: 0.0320 - val_accuracy: 0.9918\n"]}],"source":["EPOCHS = 5\n","\n","# `model.fit()` can be used as we usually do\n","hist = model.fit(train_batches,\n","                 epochs=EPOCHS,\n","                 validation_data=validation_batches)"]},{"cell_type":"markdown","metadata":{"id":"i5n_a_n9jXhC"},"source":["Once we confirm that everything is functioning correctly on a single device using the One Device Strategy, we can confidently transition to a different device or shift to a more complex distribution strategy that spans multiple devices. This progressive approach ensures that the foundational elements of the model and data handling are robust before scaling up, minimizing potential issues in more complex distributed environments. This step is key to leveraging distributed computing to enhance performance and efficiency as model demands increase."]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":0}
