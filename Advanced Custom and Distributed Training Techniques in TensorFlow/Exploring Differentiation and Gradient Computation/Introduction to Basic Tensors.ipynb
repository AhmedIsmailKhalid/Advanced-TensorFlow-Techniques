{"cells":[{"cell_type":"markdown","metadata":{"id":"OGKoGqHDSEM0"},"source":["# Basic Tensors"]},{"cell_type":"markdown","metadata":{"id":"Ev8_mJpCSEM4"},"source":["In this notebook, we will explore some of the fundamental operations that can be performed on tensors. This session is designed to help us understand how tensors function within computational graphs and how various tensor manipulations can be applied to data science and machine learning tasks. By engaging with these basic operations, we'll gain practical insights into tensor properties, manipulation techniques, and their application in more complex algorithms. Let's dive into the practical aspects of tensors to enhance our proficiency in handling these versatile data structures."]},{"cell_type":"markdown","metadata":{"id":"nHBULlIGSEM5"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jqev488WJ9-R"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"sIIXMZboUw-P"},"source":["## Some Basic Tensor Operations\n","\n","Let's create a single-dimension numpy array of size 25, containing values ranging from 0 to 24. This array will allow us to perform a variety of operations, enhancing our understanding of how numpy handles numerical data efficiently. We'll explore tasks such as indexing, slicing, and applying mathematical functions to the array elements, which are fundamental skills for any data science or machine learning application. Let's begin by setting up the array and then proceed with some basic manipulations."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1717970834794,"user":{"displayName":"Ahmed Ismail Khalid","userId":"15798079041176304147"},"user_tz":240},"id":"GkBZyS8hKNXX","outputId":"ca970948-467f-4bf9-90d7-e2fbbbfdf207"},"outputs":[{"data":{"text/plain":["array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n","       17, 18, 19, 20, 21, 22, 23, 24])"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Create a 1D uint8 NumPy array comprising of first 25 natural numbers\n","x = np.arange(0, 25)\n","x"]},{"cell_type":"markdown","metadata":{"id":"K5xv6ZeTSEM8"},"source":["Now that we have our 1-D array, the next step is to convert this array into a `tensor`. After performing this conversion, it's important to take a moment to inspect the properties and information of the newly created tensor. This examination will help us understand the structure, data type, and shape of the tensor, providing insights into how tensors operate differently from numpy arrays and preparing us for more advanced operations and manipulations in tensor-based computing environments. Let's proceed with this conversion and then delve into the details of our tensor.\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":250,"status":"ok","timestamp":1717970835043,"user":{"displayName":"Ahmed Ismail Khalid","userId":"15798079041176304147"},"user_tz":240},"id":"MYdVyiSoLPgO","outputId":"00bfcdd8-3ab3-47b2-b8a5-e10b09f80b56"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(25,), dtype=int64, numpy=\n","array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n","       17, 18, 19, 20, 21, 22, 23, 24])>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Convert NumPy array to Tensor using `tf.constant`\n","x = tf.constant(x)\n","x"]},{"cell_type":"markdown","metadata":{"id":"uCIDR2fiSEM8"},"source":["Next, we'll square each value in the tensor `x` element-wise. This simple operation will allow us to see how tensors process arithmetic computations. Letâ€™s perform this and check the results."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1717970835043,"user":{"displayName":"Ahmed Ismail Khalid","userId":"15798079041176304147"},"user_tz":240},"id":"W6BTwNJCLjV8","outputId":"0080e46b-b525-4943-a5b9-16072d5997cf"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(25,), dtype=int64, numpy=\n","array([  0,   1,   4,   9,  16,  25,  36,  49,  64,  81, 100, 121, 144,\n","       169, 196, 225, 256, 289, 324, 361, 400, 441, 484, 529, 576])>"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Square the input tensor x\n","x = tf.square(x)\n","x"]},{"cell_type":"markdown","metadata":{"id":"Iy2dXpMRSEM9"},"source":["One key feature of tensors is their ability to be reshaped. When reshaping, it's crucial to select dimensions that accommodate all the values of the tensor without altering the data itself. This flexibility allows us to adapt the tensor's structure for various data processing and machine learning tasks efficiently. Let's proceed by adjusting the shape of our tensor to better suit our needs."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1717970835248,"user":{"displayName":"Ahmed Ismail Khalid","userId":"15798079041176304147"},"user_tz":240},"id":"7nzBSX8-L0Xt","outputId":"e6bca047-a40b-412b-be39-1ae02796f45a"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(5, 5), dtype=int64, numpy=\n","array([[  0,   1,   4,   9,  16],\n","       [ 25,  36,  49,  64,  81],\n","       [100, 121, 144, 169, 196],\n","       [225, 256, 289, 324, 361],\n","       [400, 441, 484, 529, 576]])>"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Reshape tensor x into a 5 x 5 matrix.\n","x = tf.reshape(x, (5, 5))\n","x"]},{"cell_type":"markdown","metadata":{"id":"aL0rvOsDSEM-"},"source":["When reshaping a tensor, it's important to select a shape that can be exactly filled with the tensor's values. Choosing an incompatible shape will result in an error because the total number of elements must remain constant. If we encounter an error we should :\n","\n","- Observe the error message closely to understand why the reshaping failed.\n","- Adjust the shape tuple we pass to the shape parameter to ensure it matches the total number of elements in the tensor.\n","\n","\n","This process will help us learn to handle tensor dimensions effectively, ensuring smooth data manipulation and preparation for further analysis or modeling tasks. Let's try this out and make the necessary adjustments to avoid any errors."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"elapsed":1700,"status":"error","timestamp":1717970836947,"user":{"displayName":"Ahmed Ismail Khalid","userId":"15798079041176304147"},"user_tz":240},"id":"C6WI_K_XSEM-","outputId":"5b2d9add-fc14-46d9-dfcc-86f49b817efb"},"outputs":[{"ename":"InvalidArgumentError","evalue":"{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 4 values, but the requested shape has 6 [Op:Reshape]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-9d2753082afa>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Change the input to `shape` to avoid an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 4 values, but the requested shape has 6 [Op:Reshape]"]}],"source":["# Look at the error\n","# Change the input to `shape` to avoid an error\n","tmp = tf.constant([1,2,3,4])\n","tf.reshape(tmp, shape=(2,3))"]},{"cell_type":"markdown","metadata":{"id":"HGvRZmB6SEM-"},"source":["Like reshaping, we can also modify the data type of the values within a tensor. Changing the data type is particularly useful when we need to ensure compatibility with certain mathematical operations that require a specific type, or when optimizing performance by using types that consume less memory. Letâ€™s proceed to change the data type from int to float in our tensor to accommodate these needs. This conversion is straightforward but crucial for maintaining precision in computations and ensuring the smooth integration of tensor operations."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1717970864033,"user":{"displayName":"Ahmed Ismail Khalid","userId":"15798079041176304147"},"user_tz":240},"id":"VoT-jiAIL8x5","outputId":"8175d696-21dd-4873-989c-3076e21ba769"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n","array([[  0.,   1.,   4.,   9.,  16.],\n","       [ 25.,  36.,  49.,  64.,  81.],\n","       [100., 121., 144., 169., 196.],\n","       [225., 256., 289., 324., 361.],\n","       [400., 441., 484., 529., 576.]], dtype=float32)>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Cast tensor x into float32. Notice the change in the dtype.\n","x = tf.cast(x, tf.float32)\n","x"]},{"cell_type":"markdown","metadata":{"id":"ki3Dt215SEM-"},"source":["Next, we'll create a single-value float tensor. This will serve as a practical introduction to the concept of `broadcasting`. Broadcasting is a powerful mechanism that allows TensorFlow to work with tensors of different shapes by automatically expanding the smaller tensor along the larger tensor's dimensions without using extra memory. By observing how this single-value tensor interacts with another tensor of a larger size, we can better understand how `broadcasting` simplifies operations across different shaped tensors. Let's proceed with this setup and witness `broadcasting` in action."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":182,"status":"ok","timestamp":1717970865097,"user":{"displayName":"Ahmed Ismail Khalid","userId":"15798079041176304147"},"user_tz":240},"id":"EoZD6t_PSEM-","outputId":"2a0b8af8-b956-4509-92cb-86f4bb07fad9"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=2.0>"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Let's define a constant and see how broadcasting works in the following cell.\n","y = tf.constant(2, dtype=tf.float32)\n","y"]},{"cell_type":"markdown","metadata":{"id":"40RaiDK8SEM_"},"source":["Next, we'll multiply tensors `x` and `y` together. This will demonstrate how tensor multiplication is handled and allow us to inspect the results to understand the process better. Let's proceed and observe the outcome."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":175,"status":"ok","timestamp":1717970866925,"user":{"displayName":"Ahmed Ismail Khalid","userId":"15798079041176304147"},"user_tz":240},"id":"ivepGtD5MKP5","outputId":"7df55593-c08d-4adc-e787-2743af155144"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n","array([[   0.,    2.,    8.,   18.,   32.],\n","       [  50.,   72.,   98.,  128.,  162.],\n","       [ 200.,  242.,  288.,  338.,  392.],\n","       [ 450.,  512.,  578.,  648.,  722.],\n","       [ 800.,  882.,  968., 1058., 1152.]], dtype=float32)>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Multiply tensor `x` and `y`. `y` is multiplied to each element of x.\n","result = tf.multiply(x, y)\n","result"]},{"cell_type":"markdown","metadata":{"id":"-ySeHhxMSEM_"},"source":["Let's re-initialize `y` to a tensor with more values. This adjustment will allow us to explore operations involving tensors of different sizes or to prepare for more complex manipulations."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1717970867410,"user":{"displayName":"Ahmed Ismail Khalid","userId":"15798079041176304147"},"user_tz":240},"id":"8wzZ5NcMMPzD","outputId":"e61f4ebf-1649-4fcf-b7f7-ab39b8c0bc71"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(5,), dtype=float32, numpy=array([1., 2., 3., 4., 5.], dtype=float32)>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Now let's define an array that matches the number of row elements in the `x` array.\n","y = tf.constant([1, 2, 3, 4, 5], dtype=tf.float32)\n","y"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":175,"status":"ok","timestamp":1717970868603,"user":{"displayName":"Ahmed Ismail Khalid","userId":"15798079041176304147"},"user_tz":240},"id":"JBNTcRQFSEM_","outputId":"4519aa25-7506-46d2-ca01-5bc756d7d486"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n","array([[  0.,   1.,   4.,   9.,  16.],\n","       [ 25.,  36.,  49.,  64.,  81.],\n","       [100., 121., 144., 169., 196.],\n","       [225., 256., 289., 324., 361.],\n","       [400., 441., 484., 529., 576.]], dtype=float32)>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Let's see first the contents of `x` again.\n","x"]},{"cell_type":"markdown","metadata":{"id":"LM0NKRqjSEM_"},"source":["Next, we'll add the tensors x and y together. This will help us see how TensorFlow handles addition between tensors, especially looking at how each corresponding element is combined."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1717970869615,"user":{"displayName":"Ahmed Ismail Khalid","userId":"15798079041176304147"},"user_tz":240},"id":"BVlntdYnMboh","outputId":"803168a0-3977-4cb9-953e-d0a4d3adc389"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n","array([[  1.,   3.,   7.,  13.,  21.],\n","       [ 26.,  38.,  52.,  68.,  86.],\n","       [101., 123., 147., 173., 201.],\n","       [226., 258., 292., 328., 366.],\n","       [401., 443., 487., 533., 581.]], dtype=float32)>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Add tensor `x` and `y`. `y` is added element wise to each row of `x`.\n","result = x + y\n","result"]},{"cell_type":"markdown","metadata":{"id":"95GtCCN8SENA"},"source":["### The shape parameter for tf.constant\n","\n","When using `tf.constant()`, we can transform a 1D array into a multi-dimensional array by specifying the `shape` parameter. This feature is useful for structuring our data to fit specific modeling or computational needs."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":184,"status":"ok","timestamp":1717970871149,"user":{"displayName":"Ahmed Ismail Khalid","userId":"15798079041176304147"},"user_tz":240},"id":"9Jbu3FCjSENA","outputId":"d9039c71-7522-4835-b3fa-e9d33c175ae9"},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n","array([[1, 2],\n","       [3, 4]], dtype=int32)>"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["tf.constant([1,2,3,4], shape=(2,2))"]},{"cell_type":"markdown","metadata":{"id":"dQTaJTWySENA"},"source":["### The shape parameter for tf.Variable\n","\n","Note that when using `tf.Variable()`, the shape of the tensor is derived from the shape of the input array. Unlike `tf.constant()`, setting the `shape` parameter to something other than None when creating a `tf.Variable` will not reshape a 1D array into a multi-dimensional array. Attempting to do so will result in a `ValueError`. This distinction is important to remember for correctly initializing tensors as variables without encountering errors."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1717970872016,"user":{"displayName":"Ahmed Ismail Khalid","userId":"15798079041176304147"},"user_tz":240},"id":"Y7yLTJgeSENA","outputId":"c3d490af-ac00-4629-ec22-08f41315e8ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["In this `tf.Variable` creation, the initial value's shape ((4,)) is not compatible with the explicitly supplied `shape` argument ((2, 2)).\n"]}],"source":["try:\n","    # This will produce a ValueError\n","    tf.Variable([1,2,3,4], shape=(2,2))\n","except ValueError as v:\n","    # See what the ValueError says\n","    print(v)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}
