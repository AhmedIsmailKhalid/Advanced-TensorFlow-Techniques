{"cells":[{"cell_type":"markdown","metadata":{"id":"D15P--6bCrae"},"source":["# Creating a Custom Dense Layer\n","\n","In this notebook, we will advance from using simple Lambda layers to developing a custom layer that inherits from the Layer class in Keras. This type of layer allows for more sophisticated functionality, including the incorporation of trainable weights that adjust during the model's training process. Unlike the stateless operations implemented with Lambda layers, these custom layers can maintain and update state across the training lifecycle. This feature is crucial for creating complex neural network components that need to learn from the data iteratively. Let’s dive into the details of how to construct such a layer and integrate it into our model."]},{"cell_type":"markdown","metadata":{"id":"UT-i0EiyCrak"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DpioxwFXD9Is"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"lTtylm0QCrao"},"source":["## Custom Layer with weights\n","\n","To create a trainable custom layer in Keras, we start by defining a class that inherits from Keras's Layer base class. This structure allows us to construct layers with customizable behaviors and properties. In the class declaration, there are three essential methods we need to implement: __init__(), build(), and call(). These functions are critical for establishing both the structure and functionality of the layer:\n","\n","- __init__(): This method initializes the layer, setting up any parameters or sub-layers that are part of its architecture.\n","- build(self, input_shape): Called once from the first call to call(), it is where we define the weights of the layer—these weights are trainable and are what allow the layer to learn from the input data.\n","- call(self, inputs): This method contains the computation logic of the layer. It is run every time the layer is called and is where the layer's logic interacts with the input tensor to produce an output tensor.\n","\n","By defining these methods, our custom layer will not only perform specific computations but also adapt through training, thanks to its trainable weights. Let's explore how these components come together to enhance the capabilities of our neural network."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnVrzRT6BPWl"},"outputs":[],"source":["# Inherit from this base class\n","from tensorflow.keras.layers import Layer\n","\n","class SimpleDense(Layer):\n","\n","    def __init__(self, units=32):\n","        '''Initializes the instance attributes'''\n","        super(SimpleDense, self).__init__()\n","        self.units = units\n","\n","    def build(self, input_shape):\n","        '''Create the state of the layer (weights)'''\n","        # Initialize the weights\n","        w_init = tf.random_normal_initializer()\n","        self.w = tf.Variable(name=\"kernel\",\n","            initial_value=w_init(shape=(input_shape[-1], self.units),\n","                                 dtype='float32'),\n","            trainable=True)\n","\n","        # Initialize the biases\n","        b_init = tf.zeros_initializer()\n","        self.b = tf.Variable(name=\"bias\",\n","            initial_value=b_init(shape=(self.units,), dtype='float32'),\n","            trainable=True)\n","\n","    def call(self, inputs):\n","        '''Defines the computation from inputs to outputs'''\n","        return tf.matmul(inputs, self.w) + self.b"]},{"cell_type":"markdown","metadata":{"id":"G6-NaOMACrap"},"source":["Now that we've defined our custom layer, integrating it into a neural network model is straightforward. We can use the custom layer just like any standard layer provided by Keras. Below, I'll demonstrate how to incorporate our newly created custom layer into a model's architecture. Here's an example:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":195,"status":"ok","timestamp":1717962933448,"user":{"displayName":"Ahmed Ismail Khalid","userId":"15798079041176304147"},"user_tz":240},"id":"C9SO4uTACraq","outputId":"a256669c-d4e8-4070-feac-843df9f37835"},"outputs":[{"name":"stdout","output_type":"stream","text":["[<tf.Variable 'simple_dense/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[-0.05299155]], dtype=float32)>, <tf.Variable 'simple_dense/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n"]}],"source":["# Declare an instance of the class\n","my_dense = SimpleDense(units=1)\n","\n","# Define an input and feed into the layer\n","x = tf.ones((1, 1))\n","y = my_dense(x)\n","\n","# Print parameters of the base Layer class like `variables` can be used\n","print(my_dense.variables)"]},{"cell_type":"markdown","metadata":{"id":"Rgi-nMDPCras"},"source":["Now, let's apply our custom layer within a simple network to see it in action. This step will help us understand how the custom layer behaves when integrated with other standard layers in a practical setting. We'll construct a straightforward neural network that includes our custom layer to assess its performance and functionality. Here's how we can set up the network:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4607,"status":"ok","timestamp":1717962938053,"user":{"displayName":"Ahmed Ismail Khalid","userId":"15798079041176304147"},"user_tz":240},"id":"WwTPJT4DkTyW","outputId":"306389c7-f36b-4a60-be91-f0cfb0389d15"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 141ms/step\n","[[18.981592]]\n","[<tf.Variable 'simple_dense_1/kernel:0' shape=(1, 1) dtype=float32, numpy=array([[1.9973322]], dtype=float32)>, <tf.Variable 'simple_dense_1/bias:0' shape=(1,) dtype=float32, numpy=array([-0.9917294], dtype=float32)>]\n"]}],"source":["# Define the dataset\n","xs = np.array([[-1.0],  [0.0], [1.0], [2.0], [3.0], [4.0]], dtype=float)\n","ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\n","\n","\n","# Use the Sequential API to build a model with our custom layer\n","my_layer = SimpleDense(units=1)\n","model = tf.keras.Sequential([my_layer])\n","\n","# Configure and train the model\n","model.compile(optimizer='sgd', loss='mean_squared_error')\n","model.fit(xs, ys, epochs=500,verbose=0)\n","\n","# Perform inference\n","print(model.predict([10.0]))\n","\n","# See the updated state of the variables\n","print(my_layer.variables)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
