{"cells":[{"cell_type":"markdown","metadata":{"id":"1_q0HKx4Dj-z"},"source":["# Activation Functions in Custom Layers\n","\n","In this section of our tutorial, we'll enhance our ability to build custom layers by introducing an activation parameter. This addition allows our custom layer to perform nonlinear transformations, a critical aspect in learning complex patterns in data. The implementation process is straightforward, which we will walk through step-by-step. By incorporating an activation function, our custom layer becomes more flexible and powerful, making it capable of handling a broader range of tasks within neural networks. Let’s dive into how this can be achieved with a clear and concise example.In this section of our tutorial, we'll enhance our ability to build custom layers by introducing an activation parameter. This addition allows our custom layer to perform nonlinear transformations, a critical aspect in learning complex patterns in data. The implementation process is straightforward, which we will walk through step-by-step. By incorporating an activation function, our custom layer becomes more flexible and powerful, making it capable of handling a broader range of tasks within neural networks. Let’s dive into how this can be achieved with a clear and concise example."]},{"cell_type":"markdown","metadata":{"id":"E00Bvy4JDj-1"},"source":["## Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DpioxwFXD9Is"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.layers import Layer"]},{"cell_type":"markdown","metadata":{"id":"8MFckZNnDj-4"},"source":["## Adding an activation layer\n","\n","When creating a custom layer in Keras, you have the option to enhance its functionality with built-in `activation` functions. To do this, introduce an activation parameter in the `__init__()` method of your custom layer class. This parameter will allow the specification of the desired activation function using a string identifier, which can be any of the activations available in Keras.\n","\n","Once the activation parameter is specified, initialize it using the `tf.keras.activations.get()` method. This method retrieves the correct activation function based on the string identifier provided. With the activation function initialized, you can incorporate it into the layer's operations by applying it during the forward computation within the `call()` method. This setup enables the custom layer to apply a nonlinear transformation as part of its output process, enhancing its ability to model complex patterns in the data.\n","\n","By effectively integrating activation functions, your custom layer becomes versatile and powerful, capable of performing advanced computations that are essential for deep learning models."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnVrzRT6BPWl"},"outputs":[],"source":["class SimpleDense(Layer):\n","\n","    # Add an activation parameter\n","    def __init__(self, units=32, activation=None):\n","        super(SimpleDense, self).__init__()\n","        self.units = units\n","\n","        # Define the activation to get from the built-in activation layers in Keras\n","        self.activation = tf.keras.activations.get(activation)\n","\n","\n","    def build(self, input_shape):\n","        w_init = tf.random_normal_initializer()\n","        self.w = tf.Variable(name=\"kernel\",\n","            initial_value=w_init(shape=(input_shape[-1], self.units),\n","                                 dtype='float32'),\n","            trainable=True)\n","        b_init = tf.zeros_initializer()\n","        self.b = tf.Variable(name=\"bias\",\n","            initial_value=b_init(shape=(self.units,), dtype='float32'),\n","            trainable=True)\n","        super().build(input_shape)\n","\n","\n","    def call(self, inputs):\n","        # Pass the computation to the activation layer\n","        return self.activation(tf.matmul(inputs, self.w) + self.b)"]},{"cell_type":"markdown","metadata":{"id":"rGLGCQCbDj-4"},"source":["When enhancing the functionality of a custom layer in Keras, you can easily specify the desired activation function by passing a string identifier as a parameter. For instance, including 'relu' as an activation parameter within your custom layer setup will utilize the `tf.keras.activations.relu` function. This approach is streamlined, as the string identifiers for activation functions typically match their function names in Keras.\n","\n","By specifying the activation function directly through a string identifier, you integrate essential non-linear processing capabilities into the layer, which is crucial for handling complex patterns and interactions within your data. This method not only simplifies the configuration but also maintains clarity and ease of modification in your model's architecture."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":90209,"status":"ok","timestamp":1717963444189,"user":{"displayName":"Ahmed Ismail Khalid","userId":"15798079041176304147"},"user_tz":240},"id":"WwTPJT4DkTyW","outputId":"8b44765e-873c-4874-b07d-8522fa865171"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n","Epoch 1/5\n","1875/1875 [==============================] - 20s 9ms/step - loss: 0.3038 - accuracy: 0.9120\n","Epoch 2/5\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.1442 - accuracy: 0.9564\n","Epoch 3/5\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.1085 - accuracy: 0.9676\n","Epoch 4/5\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.0900 - accuracy: 0.9722\n","Epoch 5/5\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0772 - accuracy: 0.9753\n","313/313 [==============================] - 1s 2ms/step - loss: 0.0758 - accuracy: 0.9773\n"]},{"data":{"text/plain":["[0.07583901286125183, 0.9772999882698059]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["mnist = tf.keras.datasets.mnist\n","\n","(x_train, y_train),(x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","model = tf.keras.models.Sequential([\n","    tf.keras.layers.Flatten(input_shape=(28, 28)),\n","    SimpleDense(128, activation='relu'),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Dense(10, activation='softmax')\n","])\n","\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","model.fit(x_train, y_train, epochs=5)\n","model.evaluate(x_test, y_test)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":0}
